---
services:
  jupyter:
    user: jupyter
    build:
      dockerfile: ${DOCKERFILE:-Dockerfile}
      context: .
    ports:
      - "8888:8888"
    environment:
      - DEBUG=1
      - JUPYTER_SERVER=http://jupyter:8888
      - JUPYTER_BASE_URL=${JUPYTER_BASE_URL:-http://localhost:8080}
      - JUPYTER_TOKEN  # Only set in container if set in running environment
      - PYTHONPATH=/jupyter
      - ENABLE_CHECKPOINTS=true
      - TOOL_ENABLED_ASK_USER=true
      - TOOL_ENABLED_RUN_CODE=true
      # These veriables are useful when running in server mode
      # - CONFIG_TYPE=server
      # - LLM_PROVIDER_IMPORT_PATH=archytas.models.openai.OpenAIModel
      # - LLM_SERVICE_MODEL=gpt-4o
      # - LLM_SERVICE_TOKEN=${OPENAI_API_KEY}
    volumes:
      - ./beaker_kernel:/usr/local/share/jupyter/kernels/beaker_kernel
      - .:/jupyter
    command: ["beaker", "dev", "watch", "--ip", "0.0.0.0"]
  ui:
    image: node:20
    user: node
    volumes:
      - ./beaker-vue:/ui
      - ./beaker-ts:/beaker-ts
    working_dir: "/ui"
    environment:
      - PROXY=http://jupyter:8888
    ports:
      - "8080:8080"
    command: ["npm", "run", "serve"]
